

# ğŸï¸ F1 Data Analytics & Engineering Pipeline

## ğŸ“Œ Overview

This project is an end-to-end **data engineering and analytics pipeline** built to ingest, process, and analyze **Formula 1 race data**.
It focuses on designing scalable data workflows, clean data models, and analytics-ready datasets that can support downstream analysis and visualization.

The pipeline simulates a real-world data platform used for sports analytics, combining **batch ingestion, transformation, and orchestration**.

---

## ğŸ§± Architecture

**High-level flow:**

```
External APIs (Ergast / Weather)
        â†“
Ingestion Layer (Python)
        â†“
Raw Storage
        â†“
Transformation Layer (DBT)
        â†“
Analytics Tables
        â†“
Insights / Dashboards / ML-ready datasets
```

---

## ğŸ”§ Tech Stack

* **Python** â€“ data ingestion, preprocessing
* **Apache Airflow** â€“ workflow orchestration (DAGs)
* **DBT** â€“ data modeling and transformations
* **PostgreSQL** â€“ analytical storage
* **Docker & Docker Compose** â€“ local environment setup
* **GitHub** â€“ version control and collaboration

---

## ğŸ“‚ Project Structure

```
F1/
â”œâ”€â”€ dags/                  # Airflow DAG definitions
â”œâ”€â”€ dbt/                   # DBT models and transformations
â”œâ”€â”€ include/               # Shared utilities and helpers
â”œâ”€â”€ config.py              # Configuration settings
â”œâ”€â”€ docker-compose.yml     # Local orchestration
â”œâ”€â”€ requirements.txt       # Python dependencies
â”œâ”€â”€ devlog.md              # Development log and progress notes
â””â”€â”€ README.md              # Project documentation
```

---

## ğŸ“Š Data Sources

* **Ergast API**

  * Race schedules
  * Driver and constructor standings
  * Lap times and results
* **External Weather APIs** (optional enrichment)

  * Track-level weather conditions
  * Race-day context

---

## ğŸ”„ Pipeline Features

* Idempotent ingestion to avoid duplicate data
* Schema-driven transformations using DBT
* Analytics-friendly fact and dimension tables
* Modular and extensible pipeline design
* Dockerized local development environment

---

## ğŸ§  Example Analytics Use Cases

* Driver and constructor performance trends
* Lap time and pace analysis
* Pit stop strategy comparison
* Historical race comparisons
* Weather impact on race outcomes

---

## â–¶ï¸ How to Run Locally

1. Clone the repository:

   ```bash
   git clone https://github.com/ponimark/F1.git
   cd F1
   ```

2. Start services:

   ```bash
   docker-compose up
   ```

3. Access Airflow:

   ```
   http://localhost:8080
   ```

4. Run DBT models:

   ```bash
   dbt run
   ```

---

## ğŸš€ Future Improvements

* Streaming ingestion for live race data
* ML models for race pace prediction
* Visualization layer (Superset / Metabase)
* Enhanced data quality checks
* Cloud deployment (AWS/GCP)

---

## ğŸ“¬ Notes

This project is intended to demonstrate **data engineering system design**, not just analytics queries.
The emphasis is on **scalability, maintainability, and clean data modeling**.

---

### âœ… Next steps (do this now)

1. Open `README.md`
2. Paste everything above
3. Save
4. Run:

```bash
git add README.md
git commit -m "Restore project README with architecture overview"
git push
```

